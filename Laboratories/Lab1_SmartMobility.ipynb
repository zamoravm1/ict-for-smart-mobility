{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zamoravm1/ict-for-smart-mobility/blob/main/Lab1_SmartMobility.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a28123a"
      },
      "source": [
        "# Laboratory 1 - Smart Mobility"
      ],
      "id": "4a28123a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78afb5d0"
      },
      "source": [
        "## Preliminary data analysis\n",
        "\n",
        "To get used to both MongoDB and the data at disposal, investigate first the collections and get used to the document and field stored in each."
      ],
      "id": "78afb5d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45719bb"
      },
      "source": [
        "#### Import section"
      ],
      "id": "d45719bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dd62379",
        "outputId": "20e79360-1dd7-4eb8-e425-6e27ec383f09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.5.post1)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.22)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (22.1.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2022.9.24)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mapclassify\n",
            "  Downloading mapclassify-2.4.3-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from mapclassify) (2.6.3)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from mapclassify) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.3 in /usr/local/lib/python3.7/dist-packages (from mapclassify) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mapclassify) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from mapclassify) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->mapclassify) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->mapclassify) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->mapclassify) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mapclassify) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mapclassify) (1.2.0)\n",
            "Installing collected packages: mapclassify\n",
            "Successfully installed mapclassify-2.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install geopandas\n",
        "!pip install mapclassify\n",
        "import pymongo\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "from geopandas import GeoDataFrame\n",
        "from mapclassify import classify\n",
        "# from google.colab import drive\n",
        "# drive.mount('drive')"
      ],
      "id": "6dd62379"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9392d287"
      },
      "source": [
        "#### Create a mongo Client and a db"
      ],
      "id": "9392d287"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88f0009e"
      },
      "outputs": [],
      "source": [
        "client = pymongo.MongoClient('bigdatadb.polito.it:27017',\n",
        "                     username='ictts',\n",
        "                     password='Ict4SM22!',\n",
        "                     authSource='carsharing',\n",
        "                     authMechanism='SCRAM-SHA-1',\n",
        "                     ssl=True,\n",
        "                     tlsAllowInvalidCertificates=True)\n",
        "db = client['carsharing']"
      ],
      "id": "88f0009e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BtN7DuyiGjn"
      },
      "source": [
        "#### Checking db format\n"
      ],
      "id": "6BtN7DuyiGjn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DwgS0SDbN4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8c0e92-68b4-4c71-bc1c-b0cd61703523"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_id': ObjectId('5a2e8c0d2ad85324ef307f84'),\n",
              " 'init_fuel': 39,\n",
              " 'city': 'Austin',\n",
              " 'walking': {'duration': -1, 'distance': -1},\n",
              " 'vendor': 'car2go',\n",
              " 'driving': {'duration': -1, 'distance': -1},\n",
              " 'final_time': -1,\n",
              " 'plate': 'FHB 2898',\n",
              " 'engineType': 'CE',\n",
              " 'init_time': 1512999938,\n",
              " 'vin': 'WMEEJ3BA3FK799989',\n",
              " 'smartPhoneRequired': False,\n",
              " 'interior': 'GOOD',\n",
              " 'final_fuel': -1,\n",
              " 'exterior': 'GOOD',\n",
              " 'init_date': datetime.datetime(2017, 12, 11, 7, 45, 38),\n",
              " 'final_date': -1,\n",
              " 'init_address': '4707 Harmon Ave, Austin, TX 78751, USA',\n",
              " 'final_address': '',\n",
              " 'origin_destination': {'type': 'LineString',\n",
              "  'coordinates': [[-97.71452, 30.30632], [-1, -1]]},\n",
              " 'public_transport': {'duration': -1, 'distance': -1, 'arrival_time': -1}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "db[\"ActiveBookings\"].find_one()"
      ],
      "id": "7DwgS0SDbN4K"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk3MB8_F6hPD"
      },
      "source": [
        "### 1.1 How many documents are present in each collection?"
      ],
      "id": "Pk3MB8_F6hPD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "067cd608"
      },
      "outputs": [],
      "source": [
        "# Car2Go\n",
        "ActiveBooking = db[\"ActiveBookings\"]\n",
        "ActiveParkings = db[\"ActiveParkings\"]\n",
        "PermanentBookings = db[\"PermanentBookings\"]\n",
        "PermanentParkings = db[\"PermanentParkings\"]\n",
        "# Enjoy\n",
        "enjoy_ActiveBookings = db[\"enjoy_ActiveBookings\"]\n",
        "enjoy_ActiveParkings = db[\"enjoy_ActiveParkings\"]\n",
        "enjoy_PermanentBookings = db[\"enjoy_PermanentBookings\"]\n",
        "enjoy_PermanentParkings = db[\"enjoy_PermanentParkings\"]"
      ],
      "id": "067cd608"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ced89b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276688f3-9b5d-433f-fd52-4013f032d555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in ActiveBooking:  8743\n",
            "Number of documents in ActiveParkings:  4790\n",
            "Number of documents in PermanentBookings:  28180508\n",
            "Number of documents in PermanentParkings:  28312676\n",
            "Number of documents in enjoy_ActiveBookings:  0\n",
            "Number of documents in enjoy_ActiveParkings:  0\n",
            "Number of documents in enjoy_PermanentBookings:  6653472\n",
            "Number of documents in enjoy_PermanentParkings:  6689979\n"
          ]
        }
      ],
      "source": [
        "print('Number of documents in ActiveBooking: ', ActiveBooking.count_documents({}))\n",
        "print('Number of documents in ActiveParkings: ', ActiveParkings.count_documents({}))\n",
        "print('Number of documents in PermanentBookings: ', PermanentBookings.count_documents({}))\n",
        "print('Number of documents in PermanentParkings: ', PermanentParkings.count_documents({}))\n",
        "print('Number of documents in enjoy_ActiveBookings: ', enjoy_ActiveBookings.count_documents({}))\n",
        "print('Number of documents in enjoy_ActiveParkings: ', enjoy_ActiveParkings.count_documents({}))\n",
        "print('Number of documents in enjoy_PermanentBookings: ', enjoy_PermanentBookings.count_documents({}))\n",
        "print('Number of documents in enjoy_PermanentParkings: ', enjoy_PermanentParkings.count_documents({}))"
      ],
      "id": "ced89b34"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMMySDtt6wsv"
      },
      "source": [
        "### 1.2 Why the number of documents in PermanentParkings and PermanentBooking is similar?\n",
        "\n",
        "Each car should had been booked and parking in some moment, indeed, in a perfect scenary, they should be the same, since PermanentParkings and PemanentBookings corresponds to longitudinal dataset with durations of car booking periods and duration of car parking periods respectly. "
      ],
      "id": "IMMySDtt6wsv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2npa48MB8iwW"
      },
      "source": [
        "### 1.3 For which cities the system is collecting data?"
      ],
      "id": "2npa48MB8iwW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df68af7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45695367-15ba-4753-d2ef-8eacbc32cbfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Including all collections:\n",
            "['Rheinland' 'Seattle' 'Amsterdam' 'Bologna' 'Catania' 'Madrid'\n",
            " 'Vancouver' 'Montreal' 'Twin Cities' 'Austin' 'Berlin' 'Portland' 'Roma'\n",
            " 'Milano' 'Toronto' 'Denver' 'Hamburg' 'Firenze' 'Washington DC' 'Wien'\n",
            " 'Munchen' 'New York City' 'Stuttgart' 'Calgary' 'Torino' 'Frankfurt'\n",
            " 'Columbus' 'San Diego']\n"
          ]
        }
      ],
      "source": [
        "cities = []\n",
        "cities = list(set(ActiveBooking.distinct(\"city\") + ActiveParkings.distinct(\"city\") + PermanentBookings.distinct(\"city\") + \\\n",
        "                  PermanentParkings.distinct(\"city\") +  enjoy_ActiveBookings.distinct(\"city\") + enjoy_ActiveParkings.distinct(\"city\") + \\\n",
        "                  enjoy_PermanentBookings.distinct(\"city\") + enjoy_PermanentParkings.distinct(\"city\")))\n",
        "\n",
        "\n",
        "cities=np.array(cities)\n",
        "print(\"Including all collections:\\n\" + str(cities))"
      ],
      "id": "df68af7b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06rrPEBW85IM"
      },
      "source": [
        "### 1.4 When the collection started and ended? "
      ],
      "id": "06rrPEBW85IM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WweG1FUr2F1q"
      },
      "outputs": [],
      "source": [
        "First_value_cursor =  PermanentBookings.find({}, {\"init_date\": 1}).sort(\"init_date\", 1).limit(1)\n",
        "import datetime\n",
        "\n",
        "for x in First_value_cursor:\n",
        "  print(\"First date: \", x['init_date'])\n",
        "\n",
        "Last_value_cursor =  enjoy_PermanentBookings.find({}, {\"init_date\": 1}).sort(\"init_date\", -1).limit(1)\n",
        "\n",
        "for x in Last_value_cursor:\n",
        "  print(\"Last date: \", x['init_date'])\n"
      ],
      "id": "WweG1FUr2F1q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV2Q_SZ_jjB7"
      },
      "source": [
        "### 1.5 What about the timezone of the timestamps?\n",
        "\n",
        "Timestamp - GMT+1. 2016-12-13 18:40:42\n",
        "\n",
        "Date - local zone. 2016-12-13 17:40:42\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "'init_date': datetime.datetime(2018, 1, 10, 15, 10, 35)\n",
        "'init_time': 1515593435\n",
        "```"
      ],
      "id": "RV2Q_SZ_jjB7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmO0LFpJencR"
      },
      "outputs": [],
      "source": [
        "Torino_Bookings = PermanentBookings.find({'city' : 'Torino'})\n",
        "for x in Torino_Bookings:\n",
        "  print(x['init_date'],datetime.fromtimestamp(x['init_time']))\n",
        "  break\n",
        "  "
      ],
      "id": "pmO0LFpJencR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKIjzj3zKaxU"
      },
      "source": [
        "## For each city:\n",
        "\n",
        "### 1.6.1 What is the total number of cars seen in the whole period in each city? How does this relate to the fleet size at a given time?"
      ],
      "id": "GKIjzj3zKaxU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pppq3mhYG-xF"
      },
      "outputs": [],
      "source": [
        "Torino_cars = PermanentBookings.distinct(\"plate\", {'city' : 'Torino'})\n",
        "print('Number of cars in Car2Go - Torino: ', len(Torino_cars))\n",
        "enjoy_Torino_cars = enjoy_PermanentBookings.distinct(\"plate\", {'city' : 'Torino'})\n",
        "print('Number of cars in Enjoy - Torino: ' ,len(enjoy_Torino_cars))\n",
        "Denver_cars = PermanentBookings.distinct(\"plate\", {'city' : 'Denver'})\n",
        "print('Number of cars in Car2Go - Denver: ', len(Denver_cars))"
      ],
      "id": "Pppq3mhYG-xF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUMp2e-ghM4G"
      },
      "outputs": [],
      "source": [
        "start_date1 = datetime.fromisoformat('2017-01-01')\n",
        "start_unixtime1 = (time.mktime(start_date1.timetuple()))\n",
        "\n",
        "final_date1 = datetime.fromisoformat('2017-12-31')\n",
        "final_unixtime1 = (time.mktime(final_date1.timetuple()))\n",
        "\n",
        "car2go_Torino_cars2018 = PermanentBookings.distinct(\"plate\", {'city' : 'Torino', 'init_time' : {\"$gte\": start_unixtime1, \"$lte\" : final_unixtime1}})\n",
        "enjoy_Torino_cars2018 = enjoy_PermanentBookings.distinct(\"plate\", {'city' : 'Torino', 'init_time' : {\"$gte\": start_unixtime1, \"$lte\" : final_unixtime1}})\n",
        "Denver_cars2018 = PermanentBookings.distinct(\"plate\", {'city' : 'Denver', 'init_time' : {\"$gte\": start_unixtime1, \"$lte\" : final_unixtime1}})\n",
        "print('Number of cars in Car2Go - Torino: ' ,len(car2go_Torino_cars2018))\n",
        "print('Number of cars in Enjoy - Torino: ' ,len(enjoy_Torino_cars2018))\n",
        "print('Number of cars in Car2Go - Denver: ' ,len(Denver_cars2018))"
      ],
      "id": "MUMp2e-ghM4G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XDNisjRpTgd"
      },
      "source": [
        "2017\n",
        "\n",
        "Number of cars in Car2Go - Torino:  609\n",
        "\n",
        "Number of cars in Enjoy - Torino:  1552\n",
        "\n",
        "Number of cars in Car2Go - Denver:  608\n",
        "\n",
        "2018\n",
        "\n",
        "Number of cars in Enjoy - Torino:  413\n",
        "\n",
        "Number of cars in Enjoy - Torino:  641\n",
        "\n",
        "Number of cars in Enjoy - Torino:  331\n",
        "\n",
        "2019\n",
        "\n",
        "Number of cars in Car2Go - Torino:  0\n",
        "\n",
        "Number of cars in Enjoy - Torino:  328\n",
        "\n",
        "Number of cars in Car2Go - Denver:  0"
      ],
      "id": "8XDNisjRpTgd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB0f-W5_euHp"
      },
      "source": [
        "\n",
        "### 1.6.2 How many bookings have been recorded on the January 2018 in each city?"
      ],
      "id": "IB0f-W5_euHp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgAlshE62cT1"
      },
      "outputs": [],
      "source": [
        "start_date = datetime.fromisoformat('2018-01-01')\n",
        "start_unixtime = (time.mktime(start_date.timetuple()))\n",
        "final_date = datetime.fromisoformat('2018-01-31')\n",
        "final_unixtime = (time.mktime(final_date.timetuple()))\n",
        "Torino_Bookings = PermanentBookings.find({'city' : 'Torino', 'init_time' : {\"$gte\": start_unixtime, \"$lte\" : final_unixtime}})\n",
        "n = 0 \n",
        "for x in Torino_Bookings:\n",
        "  n+= 1\n",
        "print(\"Torino Bookings Jan 2018: \", n)\n",
        "\n",
        "enjoy_Torino_Bookings = enjoy_PermanentBookings.find({'city' : 'Torino', 'init_time' : {\"$gte\": start_unixtime, \"$lte\" : final_unixtime}})\n",
        "n = 0 \n",
        "for x in enjoy_Torino_Bookings:\n",
        "  n+= 1\n",
        "print(\"enjoy Torino Bookings Jan 2018: \", n)\n",
        "\n",
        "Denver_Bookings = PermanentBookings.find({'city' : 'Denver', 'init_time' : {\"$gte\": start_unixtime, \"$lte\" : final_unixtime}})\n",
        "n = 0 \n",
        "for x in Denver_Bookings:\n",
        "  n+= 1\n",
        "print(\"Denver Bookings Jan 2018: \", n)\n"
      ],
      "id": "CgAlshE62cT1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asY74XfHfLUO"
      },
      "source": [
        "# 2. Analysis of the data\n",
        "\n",
        "Consider each city of your group, and the period of time of December 1st 2017 â€“ February 28th 2018. Consider the time series (city, timestamp, duration, locations). Process it to further analyse it by producing the following plots and results:"
      ],
      "id": "asY74XfHfLUO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j43mv2MAdSR"
      },
      "outputs": [],
      "source": [
        "#Time period\n",
        "start_date = datetime.fromisoformat('2017-12-01')\n",
        "start_unixtime = (time.mktime(start_date.timetuple()))\n",
        "final_date = datetime.fromisoformat('2018-02-28')\n",
        "final_unixtime = (time.mktime(final_date.timetuple()))\n",
        "\n",
        "dfs = []\n",
        "\n",
        "# BOOKINGS DF\n",
        "Torino_Bookings = PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'origin': {'$arrayElemAt' : ['$origin_destination.coordinates', 0]}, 'destination': {'$arrayElemAt' : ['$origin_destination.coordinates', 1]}}}])\n",
        "df_bookingsTorino = pd.DataFrame(Torino_Bookings)\n",
        "dfs.append(('Bookings Torino', df_bookingsTorino))\n",
        "\n",
        "enjoy_Torino_Bookings = enjoy_PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'origin': {'$arrayElemAt' : ['$origin_destination.coordinates', 0]}, 'destination': {'$arrayElemAt' : ['$origin_destination.coordinates', 1]}}}])\n",
        "df_bookingsEnjoyTorino = pd.DataFrame(enjoy_Torino_Bookings)\n",
        "dfs.append(('Bookings Torino Enjoy', df_bookingsEnjoyTorino))\n",
        "\n",
        "Denver_Bookings = PermanentBookings.aggregate([{'$match': {'city': 'Denver', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'origin': {'$arrayElemAt' : ['$origin_destination.coordinates', 0]}, 'destination': {'$arrayElemAt' : ['$origin_destination.coordinates', 1]}}}])\n",
        "df_bookingsDenver = pd.DataFrame(Denver_Bookings)\n",
        "dfs.append(('Bookings Denver', df_bookingsDenver))\n",
        "\n",
        "\n",
        "# PARKINGS DF\n",
        "Torino_Parkings = PermanentParkings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'location': '$loc.coordinates'}}])\n",
        "df_parkingsTorino = pd.DataFrame(Torino_Parkings)\n",
        "dfs.append(('Parkings Torino', df_parkingsTorino))\n",
        "\n",
        "enjoy_Torino_Parkings = enjoy_PermanentParkings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'location': '$loc.coordinates'}}])\n",
        "df_parkingsEnjoyTorino = pd.DataFrame(enjoy_Torino_Parkings)\n",
        "dfs.append(('Parkings Torino Enjoy', df_parkingsEnjoyTorino))\n",
        "\n",
        "Denver_Parkings = PermanentParkings.aggregate([{'$match': {'city': 'Denver', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'location': '$loc.coordinates'}}])\n",
        "df_parkingsDenver = pd.DataFrame(Denver_Parkings)\n",
        "dfs.append(('Parkings Denver', df_parkingsDenver))\n"
      ],
      "id": "1j43mv2MAdSR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yYdSCQ_slQS"
      },
      "source": [
        "#### 2.1 Derive the Cumulative Distribution Function of booking/parking duration and plot them. Which  consideration can you derive from the results? \n",
        "\n",
        "a. Which of the CDF is longer? Are there some outliers?\n",
        "Booking. Yes. There is outliers due to short bookings.\n",
        "\n",
        "\n",
        "b. Does the CDF change per each city? Why? Yes. the behaviors are differents.\n",
        "\n",
        "\n",
        "c. Does the CDF change over time (e.g., aggregate per each week of data, or per each day or the week)? Why? yes."
      ],
      "id": "4yYdSCQ_slQS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGt8PQxNA4ST"
      },
      "outputs": [],
      "source": [
        "#Calculate and plot of the cdf\n",
        "def cdf_plt(label, data):\n",
        "  # getting data of the histogram\n",
        "  tmp1 = np.cumsum(data)\n",
        "  tmp2 = np.sum(data)\n",
        "  cdf = tmp1/tmp2\n",
        "  datas = np.sort(data)\n",
        "  \n",
        "  # plotting PDF and CDF\n",
        "  plt.ylabel('CDF')\n",
        "  plt.xlabel('Duration [min]')\n",
        "  plt.grid(which='both')\n",
        "  plt.xscale('log')\n",
        "  plt.plot(datas, cdf, label=label)\n",
        "  plt.legend()"
      ],
      "id": "vGt8PQxNA4ST"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYmWj7GZVVGp"
      },
      "outputs": [],
      "source": [
        "# plot of CDF in parking and booking for each city\n",
        "for plot in range(3):\n",
        "  plt.figure(plot)\n",
        "  b = dfs[plot]\n",
        "  p = dfs[3 + plot]\n",
        "  cdf_plt(b[0], b[1]['duration'].values)\n",
        "  cdf_plt(p[0], p[1]['duration'].values)\n",
        "  plt.close"
      ],
      "id": "aYmWj7GZVVGp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouuxA1dM3dVL"
      },
      "outputs": [],
      "source": [
        "#Separate each dataframe in weeks\n",
        "start_date = datetime.fromisoformat('2017-12-01')\n",
        "start_unixtime = (time.mktime(start_date.timetuple()))\n",
        "final_date = datetime.fromisoformat('2018-02-28')\n",
        "final_unixtime = (time.mktime(final_date.timetuple()))\n",
        "week_unixtime = (time.mktime(datetime.fromisoformat('2022-10-23').timetuple())) - (time.mktime(datetime.fromisoformat('2022-10-16').timetuple()))\n",
        "for tup in dfs:\n",
        "  df = tup[1]\n",
        "  conditions = []\n",
        "  values = []\n",
        "  for week in range(13):\n",
        "    conditions.append((df['timestamp'] >= start_unixtime + week_unixtime*week) & (df['timestamp'] < start_unixtime + week_unixtime*(week+1)))\n",
        "    values.append(week)\n",
        "  df['Week'] = np.select(conditions, values)\n"
      ],
      "id": "ouuxA1dM3dVL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su47odU9Rk7m"
      },
      "outputs": [],
      "source": [
        "# Create a cdf for Weeks\n",
        "for week in range(13):\n",
        "  plt.figure(week)\n",
        "  plt.title('Week' + str(week + 1))\n",
        "  for tup in dfs:\n",
        "    df = tup[1]\n",
        "    cdf_plt(tup[0], df['duration'].loc[df['Week'] == week])\n",
        "  plt.close"
      ],
      "id": "su47odU9Rk7m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmAsNKYApdhE"
      },
      "outputs": [],
      "source": [
        "def bar_per(labels, bookings, parkings, title, date):\n",
        "  x = np.arange(len(labels)) + 1  # the label locations\n",
        "  width = 0.35  # the width of the bars\n",
        "  fig, ax = plt.subplots()\n",
        "  rects1 = ax.bar(x - width/2, bookings, width, label='bookings')\n",
        "  rects2 = ax.bar(x + width/2, parkings, width, label='parkings')\n",
        "\n",
        "  # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "  ax.set_title('Number of booked/parked cars per hour in ' + title + ' '+ date)\n",
        "  ax.set_xlabel('Hour of the day')\n",
        "  ax.set_ylabel('Number of booked/parked cars')\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels, rotation=90)\n",
        "  ax.legend()\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()"
      ],
      "id": "SmAsNKYApdhE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMj0gBbsF09a"
      },
      "source": [
        "### 2.2 Consider the system utilization over time: aggregate rentals per hour of the day, and then plot the  number of booked/parked cars (or percentage of booked/parked cars) per hour versus time of day. Do you notice any outliers? Can you explain them."
      ],
      "id": "TMj0gBbsF09a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_mKc2O0c5Fl"
      },
      "outputs": [],
      "source": [
        "#Separete each dataframe in hours of the day\n",
        "date = '2017-12-01'\n",
        "start_date = datetime.fromisoformat(date)\n",
        "start_unixtime = (time.mktime(start_date.timetuple()))\n",
        "for plot in range(3):\n",
        "  hours = []\n",
        "  occurencesb = []\n",
        "  occurencesp = []\n",
        "  b = dfs[plot]\n",
        "  p = dfs[3 + plot]\n",
        "  for hour in range(24):\n",
        "    occurencesb.append(len(b[1].loc[(b[1]['timestamp'] > start_unixtime + hour*3600) & (b[1]['timestamp'] <= start_unixtime + (hour + 1)*3600)].values))\n",
        "    occurencesp.append(len(p[1].loc[(p[1]['timestamp'] > start_unixtime + hour*3600) & (p[1]['timestamp'] <= start_unixtime + (hour + 1)*3600)].values))\n",
        "    hours.append('0' + str(hour + 1) + ':00' if hour < 9 else str(hour + 1)  + ':00')\n",
        "  title = dfs[plot][1]['city'].iloc[0] if plot != 1 else 'Enjoy ' + dfs[plot][1]['city'].iloc[0]\n",
        "  bar_per(hours, occurencesb, occurencesp, title, date)\n",
        "  plt.close"
      ],
      "id": "O_mKc2O0c5Fl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG2gKi5_F_Ic"
      },
      "source": [
        "### 2.3 Derive a criterion to filter possible outliers (booking periods that are too short/too long), so to obtain  rentals from bookings, filtering system issues or problems with the data collection.\n",
        "\n",
        "Data filtered by:\n",
        "- Booking duration, min 3 minutes. Consequence of a user testing, system error\n",
        "- Booking duration, max 180 minutes. Consequence of system error.  \n",
        "- False rental, when the coordinates of initial and final position correspond. \n",
        "- Too short parking duration, consequence of a system error."
      ],
      "id": "CG2gKi5_F_Ic"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bItkwx1bI8jx"
      },
      "outputs": [],
      "source": [
        "# Duration filters\n",
        "\n",
        "# Booking time\n",
        "min_duration=5\n",
        "max_duration=180\n",
        "# False rental\n",
        "#{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}}\n",
        "\n",
        "# BOOKINGS DF FILTERED\n",
        "\n",
        "Torino_Bookings_filter=PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'moved': {'$ne': [{'$arrayElemAt' : ['$origin_destination.coordinates', 0]},{'$arrayElemAt' : ['$origin_destination.coordinates', 1]}]}}},{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}},{'$project':{'city': 1,'duration':1,'cost':{'$multiply':['$duration',0.25]}}}])\n",
        "df_bookingsTorino_filter = pd.DataFrame(Torino_Bookings_filter)\n",
        "dfs.append(('Bookings Torino filtered',df_bookingsTorino_filter))\n",
        "\n",
        "enjoy_Torino_Bookings_filter = enjoy_PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] },'moved': {'$ne': [{'$arrayElemAt' : ['$origin_destination.coordinates', 0]},{'$arrayElemAt' : ['$origin_destination.coordinates', 1]}]}}},{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}}])\n",
        "df_bookingsEnjoyTorino_filter = pd.DataFrame(enjoy_Torino_Bookings_filter)\n",
        "dfs.append(('Bookings Torino Enjoy filtered', df_bookingsEnjoyTorino_filter))\n",
        "\n",
        "Denver_Bookings_filter = PermanentBookings.aggregate([{'$match': {'city': 'Denver', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] },'moved': {'$ne': [{'$arrayElemAt' : ['$origin_destination.coordinates', 0]},{'$arrayElemAt' : ['$origin_destination.coordinates', 1]}]}}},{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}}])\n",
        "df_bookingsDenver_filter = pd.DataFrame(Denver_Bookings_filter)\n",
        "dfs.append(('Bookings Denver filtered', df_bookingsDenver_filter))\n"
      ],
      "id": "bItkwx1bI8jx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRRbFVl_X8Q6"
      },
      "outputs": [],
      "source": [
        "# Rentals per city\n",
        "\n",
        "print('Total rentals Torino Car2go: '+ str(df_bookingsTorino_filter.index.stop))\n",
        "print('Total rentals Torino Enjoy: '+ str(df_bookingsEnjoyTorino_filter.index.stop))\n",
        "print('Total rentals Denver: '+ str(df_bookingsDenver_filter.index.stop))"
      ],
      "id": "iRRbFVl_X8Q6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jduBAVQLGGqd"
      },
      "source": [
        "### 2.4 Filtering data as above, consider the system utilization over time and the CDF of booking and parking  duration. How do these change? Are you able to filter outliers efficiently for both type of events? Consider also to plot the CDF of the filtered events. How do these appear?"
      ],
      "id": "jduBAVQLGGqd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8QuEtxrR97I"
      },
      "outputs": [],
      "source": [
        "# plot of CDF in parking and booking for each city\n",
        "for plot in range(3):\n",
        "  plt.figure(plot)\n",
        "  b = dfs[plot + 6]\n",
        "  p = dfs[plot + 3]\n",
        "  cdf_plt(b[0], b[1]['duration'].values)\n",
        "  cdf_plt(p[0], p[1]['duration'].values)\n",
        "  plt.close"
      ],
      "id": "a8QuEtxrR97I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1VhKAUmR8_0"
      },
      "source": [
        "### 2.5 Filtering the data as above, compute the average, median, standard deviation, and percentiles of the booking/parking duration over time (e.g., per each day of the collection)."
      ],
      "id": "Z1VhKAUmR8_0"
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_plot(labels, mean, std, median, percentile):\n",
        "  # getting data of the histogram\n",
        "  plt.grid(which='both')\n",
        "  plt.plot(labels, mean, label='Mean')\n",
        "  plt.plot(labels, std, label='Std')\n",
        "  plt.plot(labels, median, label='Median')\n",
        "  plt.plot(labels, percentile, label='Percentile 90')\n",
        "  plt.xticks(rotation='vertical')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "Ajnb1w6o_-Lw"
      },
      "id": "Ajnb1w6o_-Lw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwRJ9i-3LnVb"
      },
      "outputs": [],
      "source": [
        "#Separete each dataframe in hours of the day\n",
        "start_date = datetime.fromisoformat('2017-12-01')\n",
        "start_unixtime = (time.mktime(start_date.timetuple()))\n",
        "for plot in range(6):\n",
        "  df = dfs[plot][1]\n",
        "  mean = []\n",
        "  std = []\n",
        "  median = []\n",
        "  percentile = []\n",
        "  dates = []\n",
        "  plt.figure()\n",
        "  plt.title(dfs[plot][0] + ' Metrics')\n",
        "  # 89\n",
        "  for day in range(35):\n",
        "    day_values = df['duration'].loc[(df['timestamp'] > start_unixtime + day*86400) & (df['timestamp'] <= start_unixtime + (day + 1)*86400)].values\n",
        "    if len(day_values) > 0:\n",
        "      mean.append(np.mean(day_values))\n",
        "      std.append(np.std(day_values, ddof=1))\n",
        "      median.append(np.median(day_values))\n",
        "      percentile.append(np.percentile(day_values, q=90))\n",
        "      date = datetime.fromtimestamp(start_unixtime + (day)*86400).strftime(\"%Y/%m/%d\")\n",
        "      dates.append(date)\n",
        "  metrics_plot(dates,mean,std,median,percentile)\n",
        "  plt.close"
      ],
      "id": "xwRJ9i-3LnVb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPcGcyqUYTPG"
      },
      "source": [
        "### 2.6 Consider one city of your collection and check the position of the cars when returned and compute the density of cars at rental ending time (the destination matrix) during different hours of the day.\n",
        "### a. Plot the parking position of cars in different times using a mapping service of your preference. For instance, how different are the destination zones on Mondays between 8-10 and 18-20? Or same time, but different day? Or weekend and weekdays?"
      ],
      "id": "WPcGcyqUYTPG"
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = datetime.fromisoformat('2017-12-04 00:00:00')\n",
        "start_unixtime = (time.mktime(start_date.timetuple()))\n",
        "print(start_unixtime)\n",
        "print(start_date)"
      ],
      "metadata": {
        "id": "E7a_x3f-oALP"
      },
      "id": "E7a_x3f-oALP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNc7udQbYdeH"
      },
      "outputs": [],
      "source": [
        "# Export location data\n",
        "start_date = datetime.fromisoformat('2017-12-04')\n",
        "start_unixtime = (time.mktime(start_date.timetuple()))\n",
        "print(start_unixtime)\n",
        "final_date1 = datetime.fromisoformat('2017-12-04')\n",
        "final_unixtime1 = (time.mktime(final_date1.timetuple()))\n",
        "\n",
        "# PermanentParkings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'location': '$loc.coordinates'}}])\n",
        "Torino_Locations = PermanentParkings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': 1512374400, '$lte': 1512381600 } }},{'$project': {'location': '$loc.coordinates'}}])\n",
        "df_locationsTorino = pd.DataFrame(Torino_Locations)\n",
        "dfs.append(('Destinations Torino', df_locationsTorino))\n",
        "print(df_locationsTorino)"
      ],
      "id": "SNc7udQbYdeH"
    },
    {
      "cell_type": "code",
      "source": [
        "start_unixtime = 1512410400\n",
        "final_unixtime = 1512417600\n",
        "\n",
        "Torino_Locations = PermanentParkings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime }}},\n",
        "                                                {'$project': {\n",
        "                                                              'lng': {'$arrayElemAt' : ['$loc.coordinates',0]},\n",
        "                                                              'lat': {'$arrayElemAt' : ['$loc.coordinates',1]}\n",
        "                                                             }}])\n",
        "df_locationsTorino = pd.DataFrame(Torino_Locations)\n",
        "dfs.append(('Destinations Torino', df_locationsTorino))\n",
        "df_locationsTorino['_id'] = df_locationsTorino['_id'].map(lambda x : x.__str__())"
      ],
      "metadata": {
        "id": "t4JEJzm--j72"
      },
      "id": "t4JEJzm--j72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siwhsKBthNlO"
      },
      "outputs": [],
      "source": [
        "geometry = gpd.points_from_xy(df_locationsTorino[\"lng\"],df_locationsTorino[\"lat\"],crs=\"EPSG:4326\")\n",
        "gdf = GeoDataFrame(df_locationsTorino, geometry=geometry)   \n",
        "gdf.explore()"
      ],
      "id": "siwhsKBthNlO"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YChSJm85RBoe"
      },
      "id": "YChSJm85RBoe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
