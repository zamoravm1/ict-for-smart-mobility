{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zamoravm1/ict-for-smart-mobility/blob/main/Lab2_SmartMobility.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "dNiaLXdUDnFC"
      },
      "source": [
        "<h1><center>ICT for Smart Mobility</center></h1>\n",
        "\n",
        "<center><font size=\"5\">Lab\t#2\t- Prediction\tusing\tARIMA\tmodels </font></center>\n",
        "\n"
      ],
      "id": "dNiaLXdUDnFC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2XwuQSpDnFQ"
      },
      "source": [
        "\n",
        "Consider the time series of rentals in the previous steps, for each city. Consider a time period of 30 days for which you have data (pay attention to stationarity – are December or January 2017 good months?).\n",
        "\n",
        "The goal of this lab is to experiment with predictions using ARIMA models, and to check how the error changes with respect to hyper-parameters. For this, you have to consider the various parameters in the \n",
        "ARIMA model training, including:\n",
        "\n",
        "    • The model parameters (p,d,q)\n",
        "    • The training windows size N (how many past samples are used for training)\n",
        "    • The training policy, i.e., expanding versus sliding windows."
      ],
      "id": "k2XwuQSpDnFQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# import section \n",
        "import pymongo\n",
        "from datetime import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0uZ_ccI4eB6N"
      },
      "id": "0uZ_ccI4eB6N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a mongoDB Client and db \n",
        "client = pymongo.MongoClient('bigdatadb.polito.it:27017',\n",
        "                     username='ictts',\n",
        "                     password='Ict4SM22!',\n",
        "                     authSource='carsharing',\n",
        "                     authMechanism='SCRAM-SHA-1',\n",
        "                     ssl=True,\n",
        "                     tlsAllowInvalidCertificates=True)\n",
        "db = client['carsharing']"
      ],
      "metadata": {
        "id": "7j21zx37fLOs"
      },
      "id": "7j21zx37fLOs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQGP2I9F2y_",
        "outputId": "a6ddae26-e083-4d39-9e47-052c2584a2d8"
      },
      "id": "9KQGP2I9F2y_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Database(MongoClient(host=['bigdatadb.polito.it:27017'], document_class=dict, tz_aware=False, connect=True, authsource='carsharing', authmechanism='SCRAM-SHA-1', tlsallowinvalidcertificates=True, tlsdisableocspendpointcheck=True, tls=True), 'carsharing')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0QciMRnDnFR"
      },
      "source": [
        "## Data collection and preprocessing\n",
        "\n",
        "In this study its aimed to predict the number of rentals per-hour \n",
        "in a given city, knowing the data collected in previous days. In order to build a time-series, its selected the data between October 1st 2017 and October 30th 2017. December and January, or even August in the case of Torino are avoid it because the behavior of the users is atypic so that data is not stationary as it is required for ARIMA models."
      ],
      "id": "Q0QciMRnDnFR"
    },
    {
      "cell_type": "code",
      "source": [
        "# choose the interval\n",
        "start_date = datetime(2017,10,1)\n",
        "start_unixtime = time.mktime(start_date.timetuple())\n",
        "# start_date_unix = 1506816000.0\n",
        "final_date = datetime(2017,10,31)\n",
        "final_unixtime = time.mktime(final_date.timetuple())\n",
        "# start_date_unix = 1509408000.0"
      ],
      "metadata": {
        "id": "WesQyGTzfZzb"
      },
      "id": "WesQyGTzfZzb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1\n",
        "\n",
        "For each city, consider the selected period of 30 days. Extract the number of rentals recorded at each \n",
        "hour – after proper filtering the outliers and those bookings that are not rentals."
      ],
      "metadata": {
        "id": "YVkFUnx2g_4p"
      },
      "id": "YVkFUnx2g_4p"
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dbs variables\n",
        "\n",
        "# Car2Go\n",
        "PermanentBookings = db[\"PermanentBookings\"]\n",
        "PermanentParkings = db[\"PermanentParkings\"]\n",
        "# Enjoy\n",
        "enjoy_PermanentBookings = db[\"enjoy_PermanentBookings\"]\n",
        "enjoy_PermanentParkings = db[\"enjoy_PermanentParkings\"]"
      ],
      "metadata": {
        "id": "yCHULTFSi0J3"
      },
      "id": "yCHULTFSi0J3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Booking data per city\n",
        "\n",
        "dfs = []\n",
        "# BOOKINGS DF\n",
        "Torino_Bookings = PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'origin': {'$arrayElemAt' : ['$origin_destination.coordinates', 0]}, 'destination': {'$arrayElemAt' : ['$origin_destination.coordinates', 1]}}}])\n",
        "df_bookingsTorino = pd.DataFrame(Torino_Bookings)\n",
        "dfs.append(('Bookings Torino', df_bookingsTorino))\n",
        "\n",
        "enjoy_Torino_Bookings = enjoy_PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'origin': {'$arrayElemAt' : ['$origin_destination.coordinates', 0]}, 'destination': {'$arrayElemAt' : ['$origin_destination.coordinates', 1]}}}])\n",
        "df_bookingsEnjoyTorino = pd.DataFrame(enjoy_Torino_Bookings)\n",
        "dfs.append(('Bookings Torino Enjoy', df_bookingsEnjoyTorino))\n",
        "\n",
        "Denver_Bookings = PermanentBookings.aggregate([{'$match': {'city': 'Denver', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'origin': {'$arrayElemAt' : ['$origin_destination.coordinates', 0]}, 'destination': {'$arrayElemAt' : ['$origin_destination.coordinates', 1]}}}])\n",
        "df_bookingsDenver = pd.DataFrame(Denver_Bookings)\n",
        "dfs.append(('Bookings Denver', df_bookingsDenver))"
      ],
      "metadata": {
        "id": "8tOjjFMygSUy"
      },
      "id": "8tOjjFMygSUy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering outliers\n",
        "\n",
        "# Booking time\n",
        "min_duration=5\n",
        "max_duration=180\n",
        "# False rental\n",
        "#{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}}\n",
        "\n",
        "# BOOKINGS DF FILTERED\n",
        "dfs_clean = []\n",
        "\n",
        "Torino_Bookings_filter=PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] }, 'moved': {'$ne': [{'$arrayElemAt' : ['$origin_destination.coordinates', 0]},{'$arrayElemAt' : ['$origin_destination.coordinates', 1]}]}}},{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}}])\n",
        "df_bookingsTorino_filter = pd.DataFrame(Torino_Bookings_filter)\n",
        "dfs_clean.append(('Bookings Torino filtered',df_bookingsTorino_filter))\n",
        "\n",
        "enjoy_Torino_Bookings_filter = enjoy_PermanentBookings.aggregate([{'$match': {'city': 'Torino', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] },'moved': {'$ne': [{'$arrayElemAt' : ['$origin_destination.coordinates', 0]},{'$arrayElemAt' : ['$origin_destination.coordinates', 1]}]}}},{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}}])\n",
        "df_bookingsEnjoyTorino_filter = pd.DataFrame(enjoy_Torino_Bookings_filter)\n",
        "dfs_clean.append(('Bookings Torino Enjoy filtered', df_bookingsEnjoyTorino_filter))\n",
        "\n",
        "Denver_Bookings_filter = PermanentBookings.aggregate([{'$match': {'city': 'Denver', 'init_time': { '$gte': start_unixtime, '$lte': final_unixtime } }},{'$project': {'city': 1, 'timestamp': '$init_time', 'duration': { '$divide': [ { '$subtract': [\"$final_time\", \"$init_time\"] }, 60 ] },'moved': {'$ne': [{'$arrayElemAt' : ['$origin_destination.coordinates', 0]},{'$arrayElemAt' : ['$origin_destination.coordinates', 1]}]}}},{'$match': {'moved':  True, 'duration':{'$gte': min_duration,'$lte': max_duration}}}])\n",
        "df_bookingsDenver_filter = pd.DataFrame(Denver_Bookings_filter)\n",
        "dfs_clean.append(('Bookings Denver filtered', df_bookingsDenver_filter))"
      ],
      "metadata": {
        "id": "U6fEDsE7iqQO"
      },
      "id": "U6fEDsE7iqQO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate per hours\n",
        "occurences_torino=[]\n",
        "occurences_torinoenjoy=[]\n",
        "occurences_denver=[]\n",
        "hours=[]\n",
        "\n",
        "for hour in range(24):\n",
        "    hours.append(\"0\"+str(hour)+\":00\" if hour < 10 else str(hour)+\":00\")\n",
        "    occurences_torino.append(dfs_clean[0][1]['timestamp'] , len(dfs_clean[0][1].loc[(dfs_clean[0][1]['timestamp'] > start_unixtime + hour*3600) & (dfs_clean[0][1]['timestamp'] <= start_unixtime + (hour + 1)*3600)].values))\n",
        "    occurences_torinoenjoy.append(len(dfs_clean[1][1].loc[(dfs_clean[1][1]['timestamp'] > start_unixtime + hour*3600) & (dfs_clean[1][1]['timestamp'] <= start_unixtime + (hour + 1)*3600)].values))\n",
        "    occurences_denver.append(len(dfs_clean[0][1].loc[(dfs_clean[0][1]['timestamp'] > start_unixtime + hour*3600) & (dfs_clean[0][1]['timestamp'] <= start_unixtime + (hour + 1)*3600)].values))"
      ],
      "metadata": {
        "id": "1h4ZgxaU0syW"
      },
      "id": "1h4ZgxaU0syW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "occurences_torino"
      ],
      "metadata": {
        "id": "pDS-HEmwQxGI",
        "outputId": "0294b746-540d-4a01-f8ea-767d07eea70a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pDS-HEmwQxGI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[58,\n",
              " 31,\n",
              " 21,\n",
              " 22,\n",
              " 26,\n",
              " 22,\n",
              " 35,\n",
              " 46,\n",
              " 76,\n",
              " 87,\n",
              " 112,\n",
              " 82,\n",
              " 86,\n",
              " 86,\n",
              " 103,\n",
              " 123,\n",
              " 105,\n",
              " 113,\n",
              " 85,\n",
              " 78,\n",
              " 64,\n",
              " 67,\n",
              " 33,\n",
              " 17]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2\n",
        "\n",
        "Check that there are no missing samples (recall – ARIMA models assume a regular time series, with no missing data). In case of missing samples – define a policy for fitting missing data. For instance, use i) the last value, or ii) the average value, or iii) replace with zeros, or iv) replace with average\n",
        "value for the given time bin, etc."
      ],
      "metadata": {
        "id": "5fiamS5x_b1e"
      },
      "id": "5fiamS5x_b1e"
    },
    {
      "cell_type": "code",
      "source": [
        "dfs[0][1]['timestamp'][0]"
      ],
      "metadata": {
        "id": "P03LVTdj5CK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07ce666-9c8f-4878-8724-e6f44ce784aa"
      },
      "id": "P03LVTdj5CK8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}